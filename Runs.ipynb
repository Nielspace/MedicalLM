{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3d0e164b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from glob import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "24f35b2e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['.DS_Store',\n",
       " 'requirements.txt',\n",
       " 'README.md',\n",
       " 'dataloader.py',\n",
       " '.ipynb_checkpoints',\n",
       " '.git',\n",
       " 'data',\n",
       " 'notebooks',\n",
       " 'Runs.ipynb']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.listdir()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "680ba68e",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_PATH = \"data\"\n",
    "\n",
    "def csv_concat(dir):\n",
    "    all_files = []\n",
    "    for root, dirs, files in os.walk(dir):\n",
    "        for name in files:\n",
    "            all_files.append(os.path.join(root, name))\n",
    "            \n",
    "    csv_files = list(filter(lambda f: f.endswith('.csv'), all_files))\n",
    "    \n",
    "    return csv_files\n",
    "\n",
    "csv_files = csv_concat(DATA_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6a8316bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f9fcbcb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read CSV files from List\n",
    "df = pd.concat(map(pd.read_csv, csv_files))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "56d800cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(16779, 3)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>notes</th>\n",
       "      <th>codes</th>\n",
       "      <th>desc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>5. Patient with Other Myositis developed a sev...</td>\n",
       "      <td>M60.8</td>\n",
       "      <td>Other myositis</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>379</th>\n",
       "      <td>10. Operative Note: A surgical intervention, a...</td>\n",
       "      <td>M40.1</td>\n",
       "      <td>Other secondary kyphosis</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1243</th>\n",
       "      <td>4. Procedure: Arthroscopic hip debridement. In...</td>\n",
       "      <td>M02.0</td>\n",
       "      <td>Arthropathy following intestinal bypass</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>5. Operative Note: The patient with spinal ent...</td>\n",
       "      <td>M46.0</td>\n",
       "      <td>Spinal enthesopathy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3751</th>\n",
       "      <td>2. synovitis, erosions, and mycotic invasion w...</td>\n",
       "      <td>M01.6</td>\n",
       "      <td>Arthritis in mycoses</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  notes  codes  \\\n",
       "20    5. Patient with Other Myositis developed a sev...  M60.8   \n",
       "379   10. Operative Note: A surgical intervention, a...  M40.1   \n",
       "1243  4. Procedure: Arthroscopic hip debridement. In...  M02.0   \n",
       "13    5. Operative Note: The patient with spinal ent...  M46.0   \n",
       "3751  2. synovitis, erosions, and mycotic invasion w...  M01.6   \n",
       "\n",
       "                                         desc  \n",
       "20                            Other myositis   \n",
       "379                  Other secondary kyphosis  \n",
       "1243  Arthropathy following intestinal bypass  \n",
       "13                        Spinal enthesopathy  \n",
       "3751                     Arthritis in mycoses  "
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def file_structuring(csv_files:list()):\n",
    "    code_file_dict = dict()\n",
    "    num_file = 0\n",
    "\n",
    "\n",
    "    for i, f in enumerate(csv_files):\n",
    "        df = pd.read_csv(f)\n",
    "        p1, p2, p3 = (df[['notes', 'code', 'desc']], \n",
    "                      df[['aug_text', 'code', 'desc']], \n",
    "                      df[['paraphrase', 'code', 'desc']])\n",
    "\n",
    "        p1.columns = ['notes', 'codes', 'desc']\n",
    "        p2.columns = ['notes', 'codes', 'desc']\n",
    "        p3.columns = ['notes', 'codes', 'desc']\n",
    "\n",
    "        df = pd.concat([p1, p2, p3], axis=0, ignore_index=True)\n",
    "        df = df[['notes', 'codes', 'desc']]\n",
    "        code_file_dict[i + 1] = df\n",
    "\n",
    "    df = pd.concat(code_file_dict.values())\n",
    "    \n",
    "    return df\n",
    "    \n",
    "df = file_structuring(csv_files)\n",
    "df = df.sample(frac=1)\n",
    "print(df.shape)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "f937ea82",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>notes</th>\n",
       "      <th>codes</th>\n",
       "      <th>desc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>165</th>\n",
       "      <td>6. Operative Note: A joint resurfacing procedu...</td>\n",
       "      <td>M46.2</td>\n",
       "      <td>Osteomyelitis of vertebra</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>189</th>\n",
       "      <td>The surgical intervention was performed on a p...</td>\n",
       "      <td>M62.3</td>\n",
       "      <td>Immobility syndrome (paraplegic)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>207</th>\n",
       "      <td>\"Contracture release surgery was performed on ...</td>\n",
       "      <td>M62.4</td>\n",
       "      <td>Contracture of muscle</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>5. Operative Note: Sacroiliitis Sacroiliac Joi...</td>\n",
       "      <td>M46.1</td>\n",
       "      <td>Sacroiliitis, not elsewhere classified</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>190</th>\n",
       "      <td>There are 9. A surgical intervention was used ...</td>\n",
       "      <td>M46.2</td>\n",
       "      <td>Osteomyelitis of vertebra</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>406</th>\n",
       "      <td>4.</td>\n",
       "      <td>M45</td>\n",
       "      <td>Ankylosing spondylitis</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3470</th>\n",
       "      <td>The procedure consisted of an operation, thoro...</td>\n",
       "      <td>M01.3</td>\n",
       "      <td>Arthritis in other bacterial diseases classifi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>161</th>\n",
       "      <td>1. AS patient diagnosed with mild disease seve...</td>\n",
       "      <td>M45</td>\n",
       "      <td>Ankylosing spondylitis</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>522</th>\n",
       "      <td>3. A minimally-invagant procedure was carried ...</td>\n",
       "      <td>M40.4</td>\n",
       "      <td>Other lordosis</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>499</th>\n",
       "      <td>There are 8. There was a surgical correction o...</td>\n",
       "      <td>M41.0</td>\n",
       "      <td>Infantile idiopathic scoliosis</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2426 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  notes  codes  \\\n",
       "165   6. Operative Note: A joint resurfacing procedu...  M46.2   \n",
       "189   The surgical intervention was performed on a p...  M62.3   \n",
       "207   \"Contracture release surgery was performed on ...  M62.4   \n",
       "48    5. Operative Note: Sacroiliitis Sacroiliac Joi...  M46.1   \n",
       "190   There are 9. A surgical intervention was used ...  M46.2   \n",
       "...                                                 ...    ...   \n",
       "406                                                  4.    M45   \n",
       "3470  The procedure consisted of an operation, thoro...  M01.3   \n",
       "161   1. AS patient diagnosed with mild disease seve...    M45   \n",
       "522   3. A minimally-invagant procedure was carried ...  M40.4   \n",
       "499   There are 8. There was a surgical correction o...  M41.0   \n",
       "\n",
       "                                                   desc  \n",
       "165                           Osteomyelitis of vertebra  \n",
       "189                   Immobility syndrome (paraplegic)   \n",
       "207                               Contracture of muscle  \n",
       "48               Sacroiliitis, not elsewhere classified  \n",
       "190                           Osteomyelitis of vertebra  \n",
       "...                                                 ...  \n",
       "406                              Ankylosing spondylitis  \n",
       "3470  Arthritis in other bacterial diseases classifi...  \n",
       "161                              Ankylosing spondylitis  \n",
       "522                                      Other lordosis  \n",
       "499                      Infantile idiopathic scoliosis  \n",
       "\n",
       "[2426 rows x 3 columns]"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[df.duplicated(['notes'], keep=False)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "cccd61c0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "63"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df.codes.unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "6e552688",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/nielspace/pytorchenv/lib/python3.10/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import nlpaug.augmenter.char as nac\n",
    "import nlpaug.augmenter.word as naw\n",
    "import nlpaug.augmenter.sentence as nas\n",
    "import nlpaug.flow as nafc\n",
    "\n",
    "from nlpaug.util import Action"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "541b0e3a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quick brown fox jumps over the lazy dog .\n"
     ]
    }
   ],
   "source": [
    "text = 'The quick brown fox jumps over the lazy dog .'\n",
    "print(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "025fec00",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original:\n",
      "The quick brown fox jumps over the lazy dog .\n",
      "Augmented Text:\n",
      "['the quick talking fox jumps for their lazy dog.', 'one quick brown fox jumps for the fleeing dog.', 'the quick brown fox jumps into this wild dog.']\n"
     ]
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "import nlpaug.augmenter.word as naw\n",
    "import nlpaug.augmenter.sentence as nas\n",
    "\n",
    "def text_aug(text, model=\"bert-base-uncased\", action=\"substitute\", \n",
    "             n_samples=1, max_length=130, min_length=30):\n",
    "    \n",
    "    if model == \"bert-base-uncased\":\n",
    "        aug = naw.ContextualWordEmbsAug(\n",
    "            model_path='bert-base-uncased', action=action)\n",
    "        augmented_text = aug.augment(text, n=n_samples)\n",
    "        \n",
    "    if action == \"summary\":\n",
    "        aug = nas.AbstSummAug(model_path='t5-base')\n",
    "        augmented_text = aug.augment(text)\n",
    "        \n",
    "    if model == \"facebook/bart-large-cnn\":\n",
    "        summarizer = pipeline(\"summarization\", model=\"facebook/bart-large-cnn\")\n",
    "        out = summarizer(text, max_length=130, min_length=30, do_sample=False)\n",
    "        augmented_text = out[\"summary_text\"]\n",
    "\n",
    "    return augmented_text\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "05a69050",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading (â€¦)lve/main/config.json: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1.21k/1.21k [00:00<00:00, 1.61MB/s]\n",
      "Downloading (â€¦)ve/main/spiece.model: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 792k/792k [00:00<00:00, 904kB/s]\n",
      "Downloading (â€¦)/main/tokenizer.json: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1.39M/1.39M [00:01<00:00, 1.27MB/s]\n",
      "/Users/nielspace/pytorchenv/lib/python3.10/site-packages/transformers/models/t5/tokenization_t5_fast.py:155: FutureWarning: This tokenizer was incorrectly instantiated with a model max length of 512 which will be corrected in Transformers v5.\n",
      "For now, this behavior is kept to avoid breaking backwards compatibility when padding/encoding with `truncation is True`.\n",
      "- Be aware that you SHOULD NOT rely on t5-base automatically truncating your input to 512 when padding/encoding.\n",
      "- If you want to encode/pad to sequences longer than 512 you can either instantiate this tokenizer with `model_max_length` or pass `max_length` when encoding/padding.\n",
      "- To avoid this warning, please instantiate this tokenizer with `model_max_length` set to your preferred value.\n",
      "  warnings.warn(\n",
      "Downloading model.safetensors: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 892M/892M [01:22<00:00, 10.8MB/s]\n",
      "Downloading (â€¦)neration_config.json: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 147/147 [00:00<00:00, 207kB/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original:\n",
      "\n",
      "The history of natural language processing (NLP) generally started in the 1950s, although work can be \n",
      "found from earlier periods. In 1950, Alan Turing published an article titled \"Computing Machinery and \n",
      "Intelligence\" which proposed what is now called the Turing test as a criterion of intelligence. \n",
      "The Georgetown experiment in 1954 involved fully automatic translation of more than sixty Russian \n",
      "sentences into English. The authors claimed that within three or five years, machine translation would\n",
      "be a solved problem. However, real progress was much slower, and after the ALPAC report in 1966, \n",
      "which found that ten-year-long research had failed to fulfill the expectations, funding for machine \n",
      "translation was dramatically reduced. Little further research in machine translation was conducted \n",
      "until the late 1980s when the first statistical machine translation systems were developed.\n",
      "\n",
      "Augmented Text:\n",
      "['the history of natural language processing (NLP) generally started in the 1950s. in 1950, Alan Turing published an article titled \"Computing Machinery and Intelligence\" in 1954, the Georgetown experiment involved fully automatic translation of more than sixty Russian sentences. real progress was much slower, and funding for machine translation was dramatically reduced.']\n"
     ]
    }
   ],
   "source": [
    "article = \"\"\"\n",
    "The history of natural language processing (NLP) generally started in the 1950s, although work can be \n",
    "found from earlier periods. In 1950, Alan Turing published an article titled \"Computing Machinery and \n",
    "Intelligence\" which proposed what is now called the Turing test as a criterion of intelligence. \n",
    "The Georgetown experiment in 1954 involved fully automatic translation of more than sixty Russian \n",
    "sentences into English. The authors claimed that within three or five years, machine translation would\n",
    "be a solved problem. However, real progress was much slower, and after the ALPAC report in 1966, \n",
    "which found that ten-year-long research had failed to fulfill the expectations, funding for machine \n",
    "translation was dramatically reduced. Little further research in machine translation was conducted \n",
    "until the late 1980s when the first statistical machine translation systems were developed.\n",
    "\"\"\"\n",
    "\n",
    "aug = nas.AbstSummAug(model_path='t5-base')\n",
    "augmented_text = aug.augment(article)\n",
    "print(\"Original:\")\n",
    "print(article)\n",
    "print(\"Augmented Text:\")\n",
    "print(augmented_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "9cc73904",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading (â€¦)okenizer_config.json: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 28.0/28.0 [00:00<00:00, 45.2kB/s]\n",
      "Downloading (â€¦)lve/main/config.json: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 483/483 [00:00<00:00, 800kB/s]\n",
      "Downloading (â€¦)solve/main/vocab.txt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 232k/232k [00:00<00:00, 499kB/s]\n",
      "Downloading (â€¦)/main/tokenizer.json: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 466k/466k [00:00<00:00, 692kB/s]\n",
      "Downloading model.safetensors: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 268M/268M [00:25<00:00, 10.6MB/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "('The quick brown fox jumps over the lazy dog .',\n",
       " ['the noisy brown fox jumps alongside the lazy fox.'])"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "aug = naw.ContextualWordEmbsAug(\n",
    "    model_path='distilbert-base-uncased', action=\"substitute\")\n",
    "augmented_text = aug.augment(text)\n",
    "text, augmented_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0095d4c0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
