{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.10","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install medspacy","metadata":{"execution":{"iopub.status.busy":"2023-05-31T14:32:34.384593Z","iopub.execute_input":"2023-05-31T14:32:34.385044Z","iopub.status.idle":"2023-05-31T14:33:34.438914Z","shell.execute_reply.started":"2023-05-31T14:32:34.385015Z","shell.execute_reply":"2023-05-31T14:33:34.437687Z"},"trusted":true},"execution_count":5,"outputs":[{"name":"stdout","text":"Collecting medspacy\n  Downloading medspacy-1.1.2.tar.gz (111 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m111.4/111.4 kB\u001b[0m \u001b[31m3.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25h  Installing build dependencies ... \u001b[?25ldone\n\u001b[?25h  Getting requirements to build wheel ... \u001b[?25ldone\n\u001b[?25h  Preparing metadata (pyproject.toml) ... \u001b[?25ldone\n\u001b[?25hRequirement already satisfied: spacy<4.0,>=3.4.1 in /opt/conda/lib/python3.10/site-packages (from medspacy) (3.5.3)\nCollecting PyRuSH>=1.0.8 (from medspacy)\n  Downloading PyRuSH-1.0.8-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (67 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m67.4/67.4 kB\u001b[0m \u001b[31m5.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hCollecting pysbd==0.3.4 (from medspacy)\n  Downloading pysbd-0.3.4-py3-none-any.whl (71 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m71.1/71.1 kB\u001b[0m \u001b[31m6.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hRequirement already satisfied: jsonschema in /opt/conda/lib/python3.10/site-packages (from medspacy) (4.17.3)\nCollecting medspacy-quickumls==3.0 (from medspacy)\n  Downloading medspacy_quickumls-3.0-py3-none-any.whl (92 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m92.1/92.1 kB\u001b[0m \u001b[31m8.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hRequirement already satisfied: numpy>=1.8.2 in /opt/conda/lib/python3.10/site-packages (from medspacy-quickumls==3.0->medspacy) (1.23.5)\nRequirement already satisfied: unidecode>=0.4.19 in /opt/conda/lib/python3.10/site-packages (from medspacy-quickumls==3.0->medspacy) (1.3.6)\nCollecting nltk>=3.3 (from medspacy-quickumls==3.0->medspacy)\n  Downloading nltk-3.8.1-py3-none-any.whl (1.5 MB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.5/1.5 MB\u001b[0m \u001b[31m29.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n\u001b[?25hCollecting pysimstring (from medspacy-quickumls==3.0->medspacy)\n  Downloading pysimstring-1.2.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.5 MB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.5/1.5 MB\u001b[0m \u001b[31m41.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n\u001b[?25hCollecting unqlite>=0.8.1 (from medspacy-quickumls==3.0->medspacy)\n  Downloading unqlite-0.9.3.tar.gz (575 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m575.5/575.5 kB\u001b[0m \u001b[31m33.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25ldone\n\u001b[?25hCollecting pytest>=6 (from medspacy-quickumls==3.0->medspacy)\n  Downloading pytest-7.3.1-py3-none-any.whl (320 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m320.5/320.5 kB\u001b[0m \u001b[31m23.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hRequirement already satisfied: six in /opt/conda/lib/python3.10/site-packages (from medspacy-quickumls==3.0->medspacy) (1.16.0)\nRequirement already satisfied: Cython<3.0,>=0.25 in /opt/conda/lib/python3.10/site-packages (from PyRuSH>=1.0.8->medspacy) (0.29.34)\nRequirement already satisfied: setuptools in /opt/conda/lib/python3.10/site-packages (from PyRuSH>=1.0.8->medspacy) (59.8.0)\nCollecting PyFastNER>=1.0.8 (from PyRuSH>=1.0.8->medspacy)\n  Downloading PyFastNER-1.0.9-py3-none-any.whl (18 kB)\nCollecting quicksectx>=0.3.5 (from PyRuSH>=1.0.8->medspacy)\n  Downloading quicksectx-0.3.5-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (311 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m311.7/311.7 kB\u001b[0m \u001b[31m22.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hRequirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /opt/conda/lib/python3.10/site-packages (from spacy<4.0,>=3.4.1->medspacy) (3.0.12)\nRequirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /opt/conda/lib/python3.10/site-packages (from spacy<4.0,>=3.4.1->medspacy) (1.0.4)\nRequirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /opt/conda/lib/python3.10/site-packages (from spacy<4.0,>=3.4.1->medspacy) (1.0.9)\nRequirement already satisfied: cymem<2.1.0,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from spacy<4.0,>=3.4.1->medspacy) (2.0.7)\nRequirement already satisfied: preshed<3.1.0,>=3.0.2 in /opt/conda/lib/python3.10/site-packages (from spacy<4.0,>=3.4.1->medspacy) (3.0.8)\nRequirement already satisfied: thinc<8.2.0,>=8.1.8 in /opt/conda/lib/python3.10/site-packages (from spacy<4.0,>=3.4.1->medspacy) (8.1.10)\nRequirement already satisfied: wasabi<1.2.0,>=0.9.1 in /opt/conda/lib/python3.10/site-packages (from spacy<4.0,>=3.4.1->medspacy) (1.1.1)\nRequirement already satisfied: srsly<3.0.0,>=2.4.3 in /opt/conda/lib/python3.10/site-packages (from spacy<4.0,>=3.4.1->medspacy) (2.4.6)\nRequirement already satisfied: catalogue<2.1.0,>=2.0.6 in /opt/conda/lib/python3.10/site-packages (from spacy<4.0,>=3.4.1->medspacy) (2.0.8)\nRequirement already satisfied: typer<0.8.0,>=0.3.0 in /opt/conda/lib/python3.10/site-packages (from spacy<4.0,>=3.4.1->medspacy) (0.7.0)\nRequirement already satisfied: pathy>=0.10.0 in /opt/conda/lib/python3.10/site-packages (from spacy<4.0,>=3.4.1->medspacy) (0.10.1)\nRequirement already satisfied: smart-open<7.0.0,>=5.2.1 in /opt/conda/lib/python3.10/site-packages (from spacy<4.0,>=3.4.1->medspacy) (6.3.0)\nRequirement already satisfied: tqdm<5.0.0,>=4.38.0 in /opt/conda/lib/python3.10/site-packages (from spacy<4.0,>=3.4.1->medspacy) (4.64.1)\nRequirement already satisfied: requests<3.0.0,>=2.13.0 in /opt/conda/lib/python3.10/site-packages (from spacy<4.0,>=3.4.1->medspacy) (2.28.2)\nRequirement already satisfied: pydantic!=1.8,!=1.8.1,<1.11.0,>=1.7.4 in /opt/conda/lib/python3.10/site-packages (from spacy<4.0,>=3.4.1->medspacy) (1.10.7)\nRequirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from spacy<4.0,>=3.4.1->medspacy) (3.1.2)\nRequirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.10/site-packages (from spacy<4.0,>=3.4.1->medspacy) (21.3)\nRequirement already satisfied: langcodes<4.0.0,>=3.2.0 in /opt/conda/lib/python3.10/site-packages (from spacy<4.0,>=3.4.1->medspacy) (3.3.0)\nRequirement already satisfied: attrs>=17.4.0 in /opt/conda/lib/python3.10/site-packages (from jsonschema->medspacy) (23.1.0)\nRequirement already satisfied: pyrsistent!=0.17.0,!=0.17.1,!=0.17.2,>=0.14.0 in /opt/conda/lib/python3.10/site-packages (from jsonschema->medspacy) (0.19.3)\nRequirement already satisfied: click in /opt/conda/lib/python3.10/site-packages (from nltk>=3.3->medspacy-quickumls==3.0->medspacy) (8.1.3)\nRequirement already satisfied: joblib in /opt/conda/lib/python3.10/site-packages (from nltk>=3.3->medspacy-quickumls==3.0->medspacy) (1.2.0)\nRequirement already satisfied: regex>=2021.8.3 in /opt/conda/lib/python3.10/site-packages (from nltk>=3.3->medspacy-quickumls==3.0->medspacy) (2023.5.5)\nRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging>=20.0->spacy<4.0,>=3.4.1->medspacy) (3.0.9)\nRequirement already satisfied: typing-extensions>=4.2.0 in /opt/conda/lib/python3.10/site-packages (from pydantic!=1.8,!=1.8.1,<1.11.0,>=1.7.4->spacy<4.0,>=3.4.1->medspacy) (4.5.0)\nCollecting iniconfig (from pytest>=6->medspacy-quickumls==3.0->medspacy)\n  Downloading iniconfig-2.0.0-py3-none-any.whl (5.9 kB)\nRequirement already satisfied: pluggy<2.0,>=0.12 in /opt/conda/lib/python3.10/site-packages (from pytest>=6->medspacy-quickumls==3.0->medspacy) (1.0.0)\nCollecting exceptiongroup>=1.0.0rc8 (from pytest>=6->medspacy-quickumls==3.0->medspacy)\n  Downloading exceptiongroup-1.1.1-py3-none-any.whl (14 kB)\nRequirement already satisfied: tomli>=1.0.0 in /opt/conda/lib/python3.10/site-packages (from pytest>=6->medspacy-quickumls==3.0->medspacy) (2.0.1)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests<3.0.0,>=2.13.0->spacy<4.0,>=3.4.1->medspacy) (2.1.1)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests<3.0.0,>=2.13.0->spacy<4.0,>=3.4.1->medspacy) (3.4)\nRequirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests<3.0.0,>=2.13.0->spacy<4.0,>=3.4.1->medspacy) (1.26.15)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests<3.0.0,>=2.13.0->spacy<4.0,>=3.4.1->medspacy) (2023.5.7)\nRequirement already satisfied: blis<0.8.0,>=0.7.8 in /opt/conda/lib/python3.10/site-packages (from thinc<8.2.0,>=8.1.8->spacy<4.0,>=3.4.1->medspacy) (0.7.9)\nRequirement already satisfied: confection<1.0.0,>=0.0.1 in /opt/conda/lib/python3.10/site-packages (from thinc<8.2.0,>=8.1.8->spacy<4.0,>=3.4.1->medspacy) (0.0.4)\nRequirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->spacy<4.0,>=3.4.1->medspacy) (2.1.2)\nBuilding wheels for collected packages: medspacy, unqlite\n  Building wheel for medspacy (pyproject.toml) ... \u001b[?25ldone\n\u001b[?25h  Created wheel for medspacy: filename=medspacy-1.1.2-py3-none-any.whl size=147920 sha256=f372170a06a7e5a8d0e93f6abb6a787c25837e3daf4005cc52db1b48b8f5a312\n  Stored in directory: /root/.cache/pip/wheels/0c/f7/e0/496f83de25d194eaa8deb94bca9ddce4573467866a7c90ff2e\n  Building wheel for unqlite (setup.py) ... \u001b[?25ldone\n\u001b[?25h  Created wheel for unqlite: filename=unqlite-0.9.3-cp310-cp310-linux_x86_64.whl size=344341 sha256=435d2dfa36dbbff25fbb6d15d8738a7734fbb4525db68682ca981de1bf6950e6\n  Stored in directory: /root/.cache/pip/wheels/cd/90/04/a3c6319ea40f7d45d36bee83fefc9a3cbe2e96a6e69860eb9b\nSuccessfully built medspacy unqlite\nInstalling collected packages: pysimstring, unqlite, quicksectx, pysbd, nltk, iniconfig, exceptiongroup, pytest, PyFastNER, PyRuSH, medspacy-quickumls, medspacy\n  Attempting uninstall: nltk\n    Found existing installation: nltk 3.2.4\n    Uninstalling nltk-3.2.4:\n      Successfully uninstalled nltk-3.2.4\n\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\npreprocessing 0.1.13 requires nltk==3.2.4, but you have nltk 3.8.1 which is incompatible.\u001b[0m\u001b[31m\n\u001b[0mSuccessfully installed PyFastNER-1.0.9 PyRuSH-1.0.8 exceptiongroup-1.1.1 iniconfig-2.0.0 medspacy-1.1.2 medspacy-quickumls-3.0 nltk-3.8.1 pysbd-0.3.4 pysimstring-1.2.1 pytest-7.3.1 quicksectx-0.3.5 unqlite-0.9.3\n\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n\u001b[0m","output_type":"stream"}]},{"cell_type":"code","source":"import numpy as np \nimport pandas as pd\nimport os\n\nimport matplotlib.pyplot as plt\nplt.rcParams.update({'font.size': 10})","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2023-05-31T14:33:34.442379Z","iopub.execute_input":"2023-05-31T14:33:34.442832Z","iopub.status.idle":"2023-05-31T14:33:34.448059Z","shell.execute_reply.started":"2023-05-31T14:33:34.442788Z","shell.execute_reply":"2023-05-31T14:33:34.447246Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"df = pd.read_csv('/kaggle/input/morticd10/codes.csv')\n\n#structuring\ndf.columns = ['prefix_codes', 'decimal', 'codes', 'description', 'long_description', 'label']","metadata":{"execution":{"iopub.status.busy":"2023-05-31T14:35:00.058858Z","iopub.execute_input":"2023-05-31T14:35:00.059812Z","iopub.status.idle":"2023-05-31T14:35:00.374270Z","shell.execute_reply.started":"2023-05-31T14:35:00.059764Z","shell.execute_reply":"2023-05-31T14:35:00.373197Z"},"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"code","source":"category_distribution = df['prefix_codes'].value_counts()\nlower_threshold = 5\nupper_threshold = 10\nfiltered_categories = category_distribution[(category_distribution > lower_threshold) & (category_distribution < upper_threshold)]\n\n# print(filtered_categories)","metadata":{"execution":{"iopub.status.busy":"2023-05-31T14:35:32.322026Z","iopub.execute_input":"2023-05-31T14:35:32.322893Z","iopub.status.idle":"2023-05-31T14:35:32.350911Z","shell.execute_reply.started":"2023-05-31T14:35:32.322851Z","shell.execute_reply":"2023-05-31T14:35:32.349561Z"},"trusted":true},"execution_count":15,"outputs":[]},{"cell_type":"code","source":"new_df = df[df['prefix_codes'].isin(filtered_categories.index)]","metadata":{"execution":{"iopub.status.busy":"2023-05-31T14:35:35.770872Z","iopub.execute_input":"2023-05-31T14:35:35.771404Z","iopub.status.idle":"2023-05-31T14:35:35.784007Z","shell.execute_reply.started":"2023-05-31T14:35:35.771365Z","shell.execute_reply":"2023-05-31T14:35:35.783011Z"},"trusted":true},"execution_count":16,"outputs":[]},{"cell_type":"code","source":"new_df = new_df.sample(frac=1, random_state=23)\nprint(f\"Size: {len(new_df)}\")\nnew_df.head()","metadata":{"execution":{"iopub.status.busy":"2023-05-31T14:35:37.020454Z","iopub.execute_input":"2023-05-31T14:35:37.020846Z","iopub.status.idle":"2023-05-31T14:35:37.040980Z","shell.execute_reply.started":"2023-05-31T14:35:37.020816Z","shell.execute_reply":"2023-05-31T14:35:37.039919Z"},"trusted":true},"execution_count":17,"outputs":[{"name":"stdout","text":"Size: 15036\n","output_type":"stream"},{"execution_count":17,"output_type":"execute_result","data":{"text/plain":"      prefix_codes decimal    codes  \\\n28706       S32463       D  S32463D   \n18763          N88       0     N880   \n4627           G11       8     G118   \n3707         E7524       1   E75241   \n31511       S42456       A  S42456A   \n\n                                             description  \\\n28706       Displ assoc transv/post fx unsp acetab, 7thD   \n18763                        Leukoplakia of cervix uteri   \n4627                            Other hereditary ataxias   \n3707                         Niemann-Pick disease type B   \n31511  Nondisp fx of lateral condyle of unsp humerus,...   \n\n                                        long_description  \\\n28706  Displaced associated transverse-posterior frac...   \n18763                        Leukoplakia of cervix uteri   \n4627                            Other hereditary ataxias   \n3707                         Niemann-Pick disease type B   \n31511  Nondisplaced fracture of lateral condyle of un...   \n\n                                                   label  \n28706  Displaced associated transverse-posterior frac...  \n18763    Other noninflammatory disorders of cervix uteri  \n4627                                   Hereditary ataxia  \n3707                                Niemann-Pick disease  \n31511  Nondisplaced fracture of lateral condyle of un...  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>prefix_codes</th>\n      <th>decimal</th>\n      <th>codes</th>\n      <th>description</th>\n      <th>long_description</th>\n      <th>label</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>28706</th>\n      <td>S32463</td>\n      <td>D</td>\n      <td>S32463D</td>\n      <td>Displ assoc transv/post fx unsp acetab, 7thD</td>\n      <td>Displaced associated transverse-posterior frac...</td>\n      <td>Displaced associated transverse-posterior frac...</td>\n    </tr>\n    <tr>\n      <th>18763</th>\n      <td>N88</td>\n      <td>0</td>\n      <td>N880</td>\n      <td>Leukoplakia of cervix uteri</td>\n      <td>Leukoplakia of cervix uteri</td>\n      <td>Other noninflammatory disorders of cervix uteri</td>\n    </tr>\n    <tr>\n      <th>4627</th>\n      <td>G11</td>\n      <td>8</td>\n      <td>G118</td>\n      <td>Other hereditary ataxias</td>\n      <td>Other hereditary ataxias</td>\n      <td>Hereditary ataxia</td>\n    </tr>\n    <tr>\n      <th>3707</th>\n      <td>E7524</td>\n      <td>1</td>\n      <td>E75241</td>\n      <td>Niemann-Pick disease type B</td>\n      <td>Niemann-Pick disease type B</td>\n      <td>Niemann-Pick disease</td>\n    </tr>\n    <tr>\n      <th>31511</th>\n      <td>S42456</td>\n      <td>A</td>\n      <td>S42456A</td>\n      <td>Nondisp fx of lateral condyle of unsp humerus,...</td>\n      <td>Nondisplaced fracture of lateral condyle of un...</td>\n      <td>Nondisplaced fracture of lateral condyle of un...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"def normalise_text (text):\n    text = text.lower() # lowercase\n    text = text.replace(r\"\\#\",\"\") # replaces hashtags\n    text = text.replace(r\"@\",\"\")\n    text = text.replace(r\"[^A-Za-z0-9()!?\\'\\`\\\"]\", \" \")\n    text = text.replace(\"\\s{2,}\", \" \")\n    return text\n\ndf['long_description'] = df['long_description'].apply(normalise_text)\ndf.head()","metadata":{"execution":{"iopub.status.busy":"2023-05-31T14:35:46.842669Z","iopub.execute_input":"2023-05-31T14:35:46.843627Z","iopub.status.idle":"2023-05-31T14:35:46.951350Z","shell.execute_reply.started":"2023-05-31T14:35:46.843584Z","shell.execute_reply":"2023-05-31T14:35:46.950263Z"},"trusted":true},"execution_count":18,"outputs":[{"execution_count":18,"output_type":"execute_result","data":{"text/plain":"  prefix_codes decimal  codes  \\\n0          A00       1   A001   \n1          A00       9   A009   \n2         A010       0  A0100   \n3         A010       1  A0101   \n4         A010       2  A0102   \n\n                                       description  \\\n0  Cholera due to Vibrio cholerae 01, biovar eltor   \n1                             Cholera, unspecified   \n2                       Typhoid fever, unspecified   \n3                               Typhoid meningitis   \n4             Typhoid fever with heart involvement   \n\n                                  long_description          label  \n0  cholera due to vibrio cholerae 01, biovar eltor        Cholera  \n1                             cholera, unspecified        Cholera  \n2                       typhoid fever, unspecified  Typhoid fever  \n3                               typhoid meningitis  Typhoid fever  \n4             typhoid fever with heart involvement  Typhoid fever  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>prefix_codes</th>\n      <th>decimal</th>\n      <th>codes</th>\n      <th>description</th>\n      <th>long_description</th>\n      <th>label</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>A00</td>\n      <td>1</td>\n      <td>A001</td>\n      <td>Cholera due to Vibrio cholerae 01, biovar eltor</td>\n      <td>cholera due to vibrio cholerae 01, biovar eltor</td>\n      <td>Cholera</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>A00</td>\n      <td>9</td>\n      <td>A009</td>\n      <td>Cholera, unspecified</td>\n      <td>cholera, unspecified</td>\n      <td>Cholera</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>A010</td>\n      <td>0</td>\n      <td>A0100</td>\n      <td>Typhoid fever, unspecified</td>\n      <td>typhoid fever, unspecified</td>\n      <td>Typhoid fever</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>A010</td>\n      <td>1</td>\n      <td>A0101</td>\n      <td>Typhoid meningitis</td>\n      <td>typhoid meningitis</td>\n      <td>Typhoid fever</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>A010</td>\n      <td>2</td>\n      <td>A0102</td>\n      <td>Typhoid fever with heart involvement</td>\n      <td>typhoid fever with heart involvement</td>\n      <td>Typhoid fever</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"import medspacy\nfrom medspacy.ner import TargetRule\nfrom medspacy.visualization import visualize_ent","metadata":{"execution":{"iopub.status.busy":"2023-05-31T14:33:36.153502Z","iopub.execute_input":"2023-05-31T14:33:36.154296Z","iopub.status.idle":"2023-05-31T14:33:48.688707Z","shell.execute_reply.started":"2023-05-31T14:33:36.154257Z","shell.execute_reply":"2023-05-31T14:33:48.687583Z"},"trusted":true},"execution_count":13,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/__init__.py:98: UserWarning: unable to load libtensorflow_io_plugins.so: unable to open file: libtensorflow_io_plugins.so, from paths: ['/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io_plugins.so']\ncaused by: ['/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io_plugins.so: undefined symbol: _ZN3tsl6StatusC1EN10tensorflow5error4CodeESt17basic_string_viewIcSt11char_traitsIcEENS_14SourceLocationE']\n  warnings.warn(f\"unable to load libtensorflow_io_plugins.so: {e}\")\n/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/__init__.py:104: UserWarning: file system plugins are not loaded: unable to open file: libtensorflow_io.so, from paths: ['/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io.so']\ncaused by: ['/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io.so: undefined symbol: _ZTVN10tensorflow13GcsFileSystemE']\n  warnings.warn(f\"file system plugins are not loaded: {e}\")\n","output_type":"stream"}]},{"cell_type":"code","source":"#","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.preprocessing import LabelEncoder\nfrom sklearn.model_selection import train_test_split\n\nX = df[['long_description']]\ny = df['prefix_codes']\n\n\nencoder = LabelEncoder()\ny = encoder.fit_transform(y)\n\n# Split the dataset into a train and temporary set\nX_temp, X_test, y_temp, y_test = train_test_split(X, y, test_size=0.2, random_state=23)\n\n# Split the temporary set into validation and train set\nX_train, X_val, y_train, y_val = train_test_split(X_temp, y_temp, test_size=0.25, random_state=23)","metadata":{"execution":{"iopub.status.busy":"2023-05-31T14:37:17.010985Z","iopub.execute_input":"2023-05-31T14:37:17.011409Z","iopub.status.idle":"2023-05-31T14:37:17.115900Z","shell.execute_reply.started":"2023-05-31T14:37:17.011375Z","shell.execute_reply":"2023-05-31T14:37:17.114811Z"},"trusted":true},"execution_count":21,"outputs":[]},{"cell_type":"code","source":"import torch\nfrom torch.utils.data import Dataset, DataLoader\nimport torchtext\n\nfrom transformers import AutoTokenizer, AutoModelForSequenceClassification\n\ntokenizer = AutoTokenizer.from_pretrained('emilyalsentzer/Bio_ClinicalBERT')\nmodel = AutoModelForSequenceClassification.from_pretrained('emilyalsentzer/Bio_ClinicalBERT', \n                                                           num_labels=len(new_df['prefix_codes'].unique()))\n","metadata":{"execution":{"iopub.status.busy":"2023-05-31T14:41:09.004470Z","iopub.execute_input":"2023-05-31T14:41:09.005005Z","iopub.status.idle":"2023-05-31T14:41:15.980126Z","shell.execute_reply.started":"2023-05-31T14:41:09.004965Z","shell.execute_reply":"2023-05-31T14:41:15.979181Z"},"trusted":true},"execution_count":33,"outputs":[{"output_type":"display_data","data":{"text/plain":"Downloading (…)lve/main/config.json:   0%|          | 0.00/385 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ad13e0a207084ec085f0aa39fac29f24"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading (…)solve/main/vocab.txt:   0%|          | 0.00/213k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"fc0a6fddbd9146eaabe6988a32341950"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading pytorch_model.bin:   0%|          | 0.00/436M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"56af48ae9f85419595122221b9760d0e"}},"metadata":{}},{"name":"stderr","text":"Some weights of the model checkpoint at emilyalsentzer/Bio_ClinicalBERT were not used when initializing BertForSequenceClassification: ['cls.seq_relationship.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight']\n- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\nSome weights of BertForSequenceClassification were not initialized from the model checkpoint at emilyalsentzer/Bio_ClinicalBERT and are newly initialized: ['classifier.bias', 'classifier.weight']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","output_type":"stream"}]},{"cell_type":"code","source":"print(f\"Input Ids: {tokenizer(X_train.iloc[100].long_description, truncation=True, padding=True)['input_ids']}\")\nprint(f\"Attention Masks: {tokenizer(X_train.iloc[100].long_description, truncation=True, padding=True)['attention_mask']}\")","metadata":{"execution":{"iopub.status.busy":"2023-05-31T14:45:49.912979Z","iopub.execute_input":"2023-05-31T14:45:49.913557Z","iopub.status.idle":"2023-05-31T14:45:49.922262Z","shell.execute_reply.started":"2023-05-31T14:45:49.913516Z","shell.execute_reply":"2023-05-31T14:45:49.921188Z"},"trusted":true},"execution_count":43,"outputs":[{"name":"stdout","text":"Input Ids: [101, 12844, 2629, 1104, 6302, 21359, 4487, 1732, 10885, 3269, 117, 5576, 24951, 15842, 117, 4194, 8107, 102]\nAttention Masks: [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n","output_type":"stream"}]},{"cell_type":"code","source":"class CustomDataset(Dataset):\n    def __init__(self, X, y, tokenizer, max_length):\n        self.data = []\n        for i in zip(X, y):\n            text, target = i[0], i[1]\n            self.data.append((text, int(target)))\n            self.tokenizer = tokenizer\n            self.max_length = max_length\n            \n\n    def __len__(self):\n        return len(self.data)\n\n    def __getitem__(self, idx):\n        text, target = self.data[idx]\n        inputs = self.tokenizer(text, padding='max_length', truncation=True, \n                                max_length=self.max_length, return_tensors='pt')\n        inputs_ids = inputs['input_ids'].squeeze(0)\n        attention_masks = inputs['attention_mask'].squeeze(0)\n        return inputs_ids, attention_masks, target ","metadata":{"execution":{"iopub.status.busy":"2023-05-31T14:38:02.649238Z","iopub.execute_input":"2023-05-31T14:38:02.650232Z","iopub.status.idle":"2023-05-31T14:38:02.659972Z","shell.execute_reply.started":"2023-05-31T14:38:02.650181Z","shell.execute_reply":"2023-05-31T14:38:02.659118Z"},"trusted":true},"execution_count":24,"outputs":[]},{"cell_type":"code","source":"sentences = new_df[\"long_description\"]\nsentences_tokenized = [tokenizer.tokenize(sentence) for sentence in sentences ]\n\nprint('Max sentence length: ', max([len(sen) for sen in sentences_tokenized]))\nmax_len = max([len(sen) for sen in sentences_tokenized])","metadata":{"execution":{"iopub.status.busy":"2023-05-31T14:46:45.572568Z","iopub.execute_input":"2023-05-31T14:46:45.573678Z","iopub.status.idle":"2023-05-31T14:46:47.595724Z","shell.execute_reply.started":"2023-05-31T14:46:45.573634Z","shell.execute_reply":"2023-05-31T14:46:47.594467Z"},"trusted":true},"execution_count":46,"outputs":[{"name":"stdout","text":"Max sentence length:  41\n","output_type":"stream"}]},{"cell_type":"code","source":"train_dataset = CustomDataset(X_train, y_train, tokenizer, max_len)\nval_dataset = CustomDataset(X_test, y_test, tokenizer, max_len)\n\nbatch_size = 2\ntrain_dataloader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\nval_dataloader = DataLoader(val_dataset, batch_size=batch_size, shuffle=True)","metadata":{"execution":{"iopub.status.busy":"2023-05-31T14:47:27.824472Z","iopub.execute_input":"2023-05-31T14:47:27.825169Z","iopub.status.idle":"2023-05-31T14:47:27.833129Z","shell.execute_reply.started":"2023-05-31T14:47:27.825131Z","shell.execute_reply":"2023-05-31T14:47:27.831892Z"},"trusted":true},"execution_count":48,"outputs":[]},{"cell_type":"code","source":"device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n\nloss_function = torch.nn.CrossEntropyLoss()\noptimizer = torch.optim.AdamW(model.parameters(), lr=1e-5)","metadata":{"execution":{"iopub.status.busy":"2023-05-31T14:48:54.476636Z","iopub.execute_input":"2023-05-31T14:48:54.477096Z","iopub.status.idle":"2023-05-31T14:48:54.485478Z","shell.execute_reply.started":"2023-05-31T14:48:54.477061Z","shell.execute_reply":"2023-05-31T14:48:54.484262Z"},"trusted":true},"execution_count":49,"outputs":[]},{"cell_type":"code","source":"model = model.to(device)","metadata":{"execution":{"iopub.status.busy":"2023-05-31T14:49:11.362787Z","iopub.execute_input":"2023-05-31T14:49:11.363181Z","iopub.status.idle":"2023-05-31T14:49:11.377616Z","shell.execute_reply.started":"2023-05-31T14:49:11.363153Z","shell.execute_reply":"2023-05-31T14:49:11.376417Z"},"trusted":true},"execution_count":50,"outputs":[]},{"cell_type":"code","source":"for epoch in range(3):  # num_train_epochs = 3\n    total_loss = 0\n    model.train()  # put the model in training mode\n    \n    for batch in train_dataloader:\n        # move batch to device\n        batch = tuple(t.to(device) for t in batch)\n        b_input_ids, b_input_mask, b_labels = batch\n        \n        # forward pass\n        outputs = model(b_input_ids, attention_mask=b_input_mask, labels=b_labels)\n        loss = outputs[0]\n        \n        # backward pass and optimization\n        optimizer.zero_grad()\n        loss.backward()\n        optimizer.step()\n        \n        total_loss += loss.item()\n    \n    avg_train_loss = total_loss / len(train_loader)\n    print(\"Average training loss: {0:.2f}\".format(avg_train_loss))","metadata":{"execution":{"iopub.status.busy":"2023-05-31T14:49:34.558749Z","iopub.execute_input":"2023-05-31T14:49:34.559166Z","iopub.status.idle":"2023-05-31T14:49:35.955235Z","shell.execute_reply.started":"2023-05-31T14:49:34.559134Z","shell.execute_reply":"2023-05-31T14:49:35.953629Z"},"trusted":true},"execution_count":52,"outputs":[{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)","Cell \u001b[0;32mIn[52], line 11\u001b[0m\n\u001b[1;32m      8\u001b[0m b_input_ids, b_input_mask, b_labels \u001b[38;5;241m=\u001b[39m batch\n\u001b[1;32m     10\u001b[0m \u001b[38;5;66;03m# forward pass\u001b[39;00m\n\u001b[0;32m---> 11\u001b[0m outputs \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mb_input_ids\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mb_input_mask\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlabels\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mb_labels\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     12\u001b[0m loss \u001b[38;5;241m=\u001b[39m outputs[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m     14\u001b[0m \u001b[38;5;66;03m# backward pass and optimization\u001b[39;00m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1502\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/transformers/models/bert/modeling_bert.py:1597\u001b[0m, in \u001b[0;36mBertForSequenceClassification.forward\u001b[0;34m(self, input_ids, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, labels, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m   1595\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39mproblem_type \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msingle_label_classification\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m   1596\u001b[0m     loss_fct \u001b[38;5;241m=\u001b[39m CrossEntropyLoss()\n\u001b[0;32m-> 1597\u001b[0m     loss \u001b[38;5;241m=\u001b[39m \u001b[43mloss_fct\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlogits\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mview\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnum_labels\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlabels\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mview\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1598\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39mproblem_type \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmulti_label_classification\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m   1599\u001b[0m     loss_fct \u001b[38;5;241m=\u001b[39m BCEWithLogitsLoss()\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1502\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/nn/modules/loss.py:1174\u001b[0m, in \u001b[0;36mCrossEntropyLoss.forward\u001b[0;34m(self, input, target)\u001b[0m\n\u001b[1;32m   1173\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor, target: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[0;32m-> 1174\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcross_entropy\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtarget\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mweight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1175\u001b[0m \u001b[43m                           \u001b[49m\u001b[43mignore_index\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mignore_index\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreduction\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreduction\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1176\u001b[0m \u001b[43m                           \u001b[49m\u001b[43mlabel_smoothing\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlabel_smoothing\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/nn/functional.py:3029\u001b[0m, in \u001b[0;36mcross_entropy\u001b[0;34m(input, target, weight, size_average, ignore_index, reduce, reduction, label_smoothing)\u001b[0m\n\u001b[1;32m   3027\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m size_average \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mor\u001b[39;00m reduce \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   3028\u001b[0m     reduction \u001b[38;5;241m=\u001b[39m _Reduction\u001b[38;5;241m.\u001b[39mlegacy_get_string(size_average, reduce)\n\u001b[0;32m-> 3029\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_C\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_nn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcross_entropy_loss\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtarget\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m_Reduction\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_enum\u001b[49m\u001b[43m(\u001b[49m\u001b[43mreduction\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mignore_index\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlabel_smoothing\u001b[49m\u001b[43m)\u001b[49m\n","\u001b[0;31mIndexError\u001b[0m: Target 17693 is out of bounds."],"ename":"IndexError","evalue":"Target 17693 is out of bounds.","output_type":"error"}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}